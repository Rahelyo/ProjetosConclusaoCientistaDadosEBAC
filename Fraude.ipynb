{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew_dJAPZicjh"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# IMPORTAÇÃO DE BIBLIOTECAS\n",
        "# ==============================================================================\n",
        "print(\"Iniciando o projeto de Detecção de Fraudes...\")\n",
        "print(\"Carregando bibliotecas...\")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Para a Etapa 2: Preparação\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Para a Etapa 4 e 5: Modelagem e Avaliação\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "# Configurações de visualização\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n",
        "print(\"Bibliotecas carregadas com sucesso.\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 1: Entendimento do Problema e dos Dados\n",
        "# ==============================================================================\n",
        "print(\"--- INICIANDO ETAPA 1: Entendimento do Problema e dos Dados ---\")\n",
        "\n",
        "# Carregar o conjunto de dados a partir do arquivo .xlsb\n",
        "file_name = \"mercadoFinanceiro.xlsb\"\n",
        "try:\n",
        "    df = pd.read_excel(file_name, engine='pyxlsb', sheet_name=0)\n",
        "    print(f\"Arquivo '{file_name}' carregado com sucesso!\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    exit()\n",
        "except ImportError:\n",
        "    print(\"Erro: A biblioteca 'pyxlsb' é necessária. Instale-a com: pip install pyxlsb\")\n",
        "    exit()\n",
        "\n",
        "# Exploração Inicial dos Dados\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n2. Informações Gerais do DataFrame (tipos de dados e valores nulos):\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n3. Resumo Estatístico das Variáveis Numéricas:\")\n",
        "print(df.describe().T)\n",
        "\n",
        "# VERIFICAÇÃO CRÍTICA: Identificar a coluna Alvo e o Desbalanceamento\n",
        "target_column = None\n",
        "possible_targets = ['Class', 'fraude', 'isFraud', 'Fraud', 'is_fraud', 'FRAUDE']\n",
        "for col in possible_targets:\n",
        "    if col in df.columns:\n",
        "        target_column = col\n",
        "        break\n",
        "\n",
        "if not target_column:\n",
        "    print(\"\\nERRO CRÍTICO: Não foi possível identificar a coluna alvo (ex: 'Class', 'fraude').\")\n",
        "    exit()\n",
        "\n",
        "# --- CORREÇÃO APLICADA (PARTE 1) ---\n",
        "# Converter a coluna alvo para tipo numérico (inteiro).\n",
        "# Isso corrige o erro 'ValueError' e garante que os modelos de ML\n",
        "# recebam 0 e 1 como números, não como texto.\n",
        "try:\n",
        "    df[target_column] = df[target_column].astype(int)\n",
        "    print(f\"\\nColuna alvo '{target_column}' encontrada e convertida para tipo numérico (inteiro).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nERRO ao converter a coluna alvo para inteiro: {e}\")\n",
        "    print(\"Verifique os dados na coluna alvo.\")\n",
        "    exit()\n",
        "# --- FIM DA CORREÇÃO (PARTE 1) ---\n",
        "\n",
        "print(f\"\\n4. Análise de Desbalanceamento da Coluna Alvo ('{target_column}'):\")\n",
        "class_counts = df[target_column].value_counts()\n",
        "class_perc = df[target_column].value_counts(normalize=True) * 100\n",
        "\n",
        "print(f\"Contagem de Classes:\\n{class_counts}\")\n",
        "print(f\"\\nPercentual de Classes:\\n{class_perc}\")\n",
        "\n",
        "# Visualização do Desbalanceamento\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# --- CORREÇÃO APLICADA (PARTE 2) ---\n",
        "# Atualizada a sintaxe do Seaborn conforme o aviso (deprecation warning)\n",
        "# Agora que a coluna é numérica, a paleta {0:..., 1:...} funciona.\n",
        "ax = sns.countplot(\n",
        "    x=target_column,\n",
        "    data=df,\n",
        "    hue=target_column,  # Adicionado conforme aviso\n",
        "    palette={0: \"#a0d\", 1: \"#f0a\"},  # Paleta com chaves numéricas\n",
        "    legend=False  # Adicionado conforme aviso\n",
        ")\n",
        "# --- FIM DA CORREÇÃO (PARTE 2) ---\n",
        "\n",
        "plt.title('Distribuição das Classes (0 = Normal, 1 = Fraude)', fontsize=16)\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Contagem')\n",
        "# Adicionar anotações de percentual\n",
        "total = len(df)\n",
        "for p in ax.patches:\n",
        "    percentage = '{:.4f}%'.format(100 * p.get_height() / total)\n",
        "    x = p.get_x() + p.get_width() / 2\n",
        "    y = p.get_height()\n",
        "    ax.annotate(percentage, (x, y), ha='center', va='bottom', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 1 ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 2: Preparação dos Dados\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 2: Preparação dos Dados ---\")\n",
        "\n",
        "# 1. Tratamento de Valores Faltantes\n",
        "print(f\"1. Verificando valores nulos: {df.isnull().sum().any()}\")\n",
        "\n",
        "# 2. Normalização e Padronização\n",
        "if 'Time' in df.columns:\n",
        "    df = df.drop('Time', axis=1)\n",
        "    print(\"2. Coluna 'Time' removida.\")\n",
        "\n",
        "# Separar features (X) e alvo (y)\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]  # 'y' agora é garantidamente numérico\n",
        "\n",
        "# Padronizar as features (X)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"3. Todas as features foram padronizadas (StandardScaler).\")\n",
        "print(\"Visualização das features padronizadas:\")\n",
        "print(X_scaled.head())\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 2 ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 3: Análise Exploratória de Dados (EDA)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 3: Análise Exploratória de Dados ---\")\n",
        "\n",
        "# 1. Análise de Correlação\n",
        "print(\"1. Analisando correlação das features com a Fraude...\")\n",
        "corr_matrix = df.corr()\n",
        "corr_target = corr_matrix[target_column].sort_values(ascending=False)\n",
        "print(\"Correlações mais fortes com a Fraude:\")\n",
        "print(corr_target.head(5))\n",
        "print(corr_target.tail(5))\n",
        "\n",
        "# 2. Visualização das Features Principais\n",
        "if 'Amount' in df.columns:\n",
        "    print(\"\\n2. Visualizando distribuição de 'Amount' por classe...\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # --- CORREÇÃO APLICADA (PARTE 3) ---\n",
        "    # Aplicando a mesma correção de sintaxe do Seaborn ao boxplot\n",
        "    sns.boxplot(\n",
        "        x=target_column,\n",
        "        y='Amount',\n",
        "        data=df,\n",
        "        showfliers=False,\n",
        "        hue=target_column,  # Adicionado\n",
        "        palette={0: \"#a0d\", 1: \"#f0a\"},  # Chaves numéricas\n",
        "        legend=False  # Adicionado\n",
        "    )\n",
        "    # --- FIM DA CORREÇÃO (PARTE 3) ---\n",
        "\n",
        "    plt.title('Distribuição do Valor da Transação (Amount) por Classe', fontsize=16)\n",
        "    plt.xlabel('Classe (0 = Normal, 1 = Fraude)')\n",
        "    plt.ylabel('Valor da Transação (Amount)')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\n2. Coluna 'Amount' não encontrada para visualização.\")\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 3 ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 4: Seleção de Modelos e Algoritmos\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 4: Seleção de Modelos e Algoritmos ---\")\n",
        "\n",
        "# 1. Divisão de Dados em Treinamento e Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # Essencial para dados desbalanceados\n",
        ")\n",
        "\n",
        "print(\"1. Dados divididos em Treino (80%) e Teste (20%) com estratificação.\")\n",
        "print(f\"   - Fraudes no treino: {sum(y_train)} ({sum(y_train) / len(y_train) * 100:.2f}%)\")\n",
        "print(f\"   - Fraudes no teste: {sum(y_test)} ({sum(y_test) / len(y_test) * 100:.2f}%)\")\n",
        "\n",
        "# 2. Escolha de Algoritmos\n",
        "models = {\n",
        "    \"Regressão Logística\": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
        "}\n",
        "print(\"\\n2. Modelos selecionados: Regressão Logística e Random Forest (com 'class_weight=balanced').\")\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 4 ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 5: Treinamento e Avaliação do Modelo\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 5: Treinamento e Avaliação do Modelo ---\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Loop para treinar e avaliar cada modelo\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Treinando e Avaliando: {name} ---\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Avaliação\n",
        "    print(\"Métricas de Avaliação (Foco em Recall e Precisão):\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Fraude (1)']))\n",
        "\n",
        "    auc_roc = roc_auc_score(y_test, y_proba)\n",
        "    auc_pr = average_precision_score(y_test, y_proba)  # Mais importante em dados desbalanceados\n",
        "\n",
        "    results[name] = {\n",
        "        \"AUC-ROC\": auc_roc,\n",
        "        \"AUC-PR (Média Precisão)\": auc_pr\n",
        "    }\n",
        "\n",
        "    print(f\"AUC-ROC (distingue classes): {auc_roc:.4f}\")\n",
        "    print(f\"AUC-PR (foco na classe positiva): {auc_pr:.4f}\")\n",
        "\n",
        "    # Visualização de Resultados (Etapa 7)\n",
        "\n",
        "    # 1. Matriz de Confusão\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Prev. Normal', 'Prev. Fraude'],\n",
        "                yticklabels=['Real Normal', 'Real Fraude'])\n",
        "    plt.title(f'Matriz de Confusão - {name}', fontsize=16)\n",
        "    plt.ylabel('Verdadeiro')\n",
        "    plt.xlabel('Previsto')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Análise da Matriz de Confusão ({name}):\")\n",
        "    print(f\"   - Verdadeiros Negativos (Normais detectados): {cm[0][0]}\")\n",
        "    print(f\"   - Falsos Positivos (Normais bloqueados): {cm[0][1]} <- Ruim para experiência\")\n",
        "    print(f\"   - Falsos Negativos (Fraudes perdidas): {cm[1][0]} <- Ruim para o banco\")\n",
        "    print(f\"   - Verdadeiros Positivos (Fraudes detectadas): {cm[1][1]}\")\n",
        "\n",
        "# 2. Curva Precision-Recall (Etapa 7)\n",
        "plt.figure(figsize=(10, 7))\n",
        "for name, model in models.items():\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
        "    avg_prec = average_precision_score(y_test, y_proba)\n",
        "    plt.plot(recall, precision, label=f'{name} (AUC-PR = {avg_prec:.3f})')\n",
        "\n",
        "plt.title('Curva Precision-Recall (P-R)', fontsize=16)\n",
        "plt.xlabel('Recall (Sensibilidade - % de fraudes pegas)')\n",
        "plt.ylabel('Precision (% de alertas corretos)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Comparação Final do Desempenho dos Modelos ---\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df.sort_values(by=\"AUC-PR (Média Precisão)\", ascending=False))\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 5 ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 6 e 7: Ajuste Final e Interpretação\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 6 e 7: Ajuste Final e Interpretação ---\")\n",
        "\n",
        "# 1. Refinamento (Ajuste Final)\n",
        "best_model = models[\"Random Forest\"]\n",
        "print(\"1. Modelo 'Random Forest' selecionado como final para interpretação.\")\n",
        "\n",
        "# 2. Interpretação dos Resultados (Feature Importance)\n",
        "importances = best_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n2. Importância das Features (O que o modelo olha?):\")\n",
        "print(feature_importance_df.head(10))\n",
        "\n",
        "# 3. Criação de Visualização Impactante (Etapa 7)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    x='importance',\n",
        "    y='feature',\n",
        "    data=feature_importance_df.head(10),\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Top 10 Features Mais Importantes para Detecção de Fraude', fontsize=16)\n",
        "plt.xlabel('Nível de Importância')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# 4. Relatório Final e Comunicação (Etapa 7)\n",
        "print(\"\\n--- Relatório Final e Recomendações (Tradução para Stakeholder) ---\")\n",
        "print(\"\"\"\n",
        "Insight 1: O Problema Central está Confirmado (Etapa 1)\n",
        "Os dados são extremamente desbalanceados. Com 99.82% de transações normais contra 0.17% de\n",
        "fraudes:\n",
        "\n",
        "A métrica Acurácia é inútil. Um modelo que sempre diz \"Normal\" teria 99.82% de acurácia,\n",
        "mas seria um fracasso.\n",
        "\n",
        "O sucesso do projeto depende 100% das métricas Precisão e Recall.\n",
        "\n",
        "Insight 2: (Etapa 3)\n",
        "A análise de correlação mostra que nenhuma variável sozinha é capaz de prever fraude.\n",
        "As correlações mais fortes (ex: V4 com 0.036 e V12 com -0.040) são muito fracas.\n",
        "\n",
        "Conclusão: É impossível criar uma regra simples (ex: \"se V12 < -5, é fraude\").\n",
        "Isso prova a necessidade de um modelo de Machine Learning complexo, como o Random Forest,\n",
        "que é capaz de encontrar padrões combinando múltiplas variáveis.\n",
        "\n",
        "Insight 3: A Batalha dos Modelos - O Trade-Off Crítico (Etapa 5)\n",
        "Este é o insight mais importante para o gestor de risco. Você tem dois modelos com duas\n",
        "estratégias totalmente diferentes:\n",
        "\n",
        "A) Regressão Logística (O \"Guarda Agressivo\")\n",
        "\n",
        "Recall (Fraude): 87% - EXCELENTE. Ele pegou 85 das 98 fraudes. O banco perdeu pouco\n",
        "dinheiro (Falsos Negativos: 13).\n",
        "\n",
        "Precisão (Fraude): 2% - PÉSSIMO. Para pegar essas 85 fraudes, ele bloqueou 5.239 clientes\n",
        "inocentes (Falsos Positivos).\n",
        "\n",
        "Conclusão de Negócio: Este modelo é inviável. Ele cumpre a meta de \"pegar fraudes\", mas\n",
        " destrói a experiência do cliente, indo contra a segunda parte do briefing.\n",
        "\n",
        "B) Random Forest (O \"Cirurgião Preciso\")\n",
        "\n",
        "Recall (Fraude): 62% - BOM. Ele pegou 61 das 98 fraudes. Não é tão bom quanto o outro modelo,\n",
        "pois 37 fraudes passaram (Falsos Negativos).\n",
        "\n",
        "Precisão (Fraude): 86% - EXCEPCIONAL. O modelo tem altíssima confiança. Quando ele diz \"isto é\n",
        "fraude\", ele está certo 86% das vezes. Ele bloqueou apenas 10 clientes inocentes.\n",
        "\n",
        "Conclusão de Negócio: Este modelo é excelente e viável. Ele equilibra perfeitamente as\n",
        "duas metas do briefing: protege o cliente (poucos falsos positivos) e ainda captura a\n",
        "maioria das fraudes.\n",
        "\n",
        "Insight 4: A Métrica Correta Confirma a Escolha (Etapa 5)\n",
        "A \"Comparação Final\" mata a charada.\n",
        "\n",
        "O AUC-ROC é parecido para os dois (0.94), pois ele é \"enganado\" pela enorme quantidade de\n",
        "casos normais (classe 0).\n",
        "\n",
        "A AUC-PR (Média Precisão) é a métrica mais importante em dados desbalanceados.\n",
        "\n",
        "Random Forest (0.77) é astronomicamente melhor que a Regressão Logística (0.20) nesta métrica,\n",
        "confirmando que é o modelo superior para este problema.\n",
        "\n",
        "Insight 5: Agora Sabemos Onde Olhar (Etapa 7)\n",
        "O Random Forest nos diz quais são as pistas. As 5 features mais importantes que o modelo usa\n",
        "para \"decidir\" se algo é fraude são:\n",
        "\n",
        "V12\n",
        "\n",
        "V4\n",
        "\n",
        "V3\n",
        "\n",
        "V14\n",
        "\n",
        "V11\n",
        "\n",
        "Mesmo que essas features sejam anonimizadas (comuns em dados financeiros por privacidade),\n",
        "a equipe de risco agora sabe que as combinações dessas 5 variáveis são os indicadores mais\n",
        "fortes de fraude.\n",
        "\n",
        "Resumo da Conclusão (Para o Gestor de Risco):\n",
        "\"Conseguimos construir um modelo (Random Forest) que atinge o equilíbrio perfeito entre\n",
        "segurança e experiência do cliente. Ele bloqueia apenas 10 clientes inocentes para cada\n",
        "56.000 transações e, ao mesmo tempo, identifica corretamente 86% dos alertas que gera,\n",
        "capturando mais de 60% de todas as tentativas de fraude. O modelo aprendeu que as variáveis V12,\n",
        " V4 e V3 são os principais indicadores de risco.\"\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n--- PROJETO CONCLUÍDO ---\")"
      ]
    }
  ]
}