{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew_dJAPZicjh"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# ETAPA 1: Entendimento do Problema e dos Dados\n",
        "# ==============================================================================\n",
        "print(\"--- INICIANDO ETAPA 1: Entendimento do Problema e dos Dados ---\")\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definir estilo dos gráficos\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Carregar o conjunto de dados a partir do arquivo CSV\n",
        "try:\n",
        "    df = pd.read_csv('Base_M43_Pratique_LOL_RANKED_WIN.csv')\n",
        "    print(\"Arquivo CSV carregado com sucesso!\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: O arquivo 'Base_M43_Pratique_LOL_RANKED_WIN.csv' não foi encontrado.\")\n",
        "    exit() # Encerra o script se o arquivo não for encontrado\n",
        "\n",
        "# Exploração Inicial dos Dados\n",
        "print(\"--- Análise Inicial do DataFrame ---\")\n",
        "print(\"\\n1. Visualização das 5 primeiras linhas:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n2. Informações Gerais do DataFrame (tipos de dados e valores nulos):\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n3. Resumo Estatístico das Variáveis Numéricas:\")\n",
        "print(df.describe().T)\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 1 ---\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 2: Preparação dos Dados\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 2: Preparação dos Dados ---\")\n",
        "\n",
        "# 1. Tratamento de Valores Faltantes (Verificação)\n",
        "print(\"1. Verificação de valores nulos:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"Nenhum valor nulo encontrado. Nenhuma ação necessária.\\n\")\n",
        "\n",
        "# 2. Remover 'gameId'\n",
        "df = df.drop('gameId', axis=1)\n",
        "print(\"2. Coluna 'gameId' removida do conjunto de dados.\\n\")\n",
        "\n",
        "# 3. Separação das variáveis: Features (X) e Alvo (y)\n",
        "X = df.drop('blueWins', axis=1)\n",
        "y = df['blueWins']\n",
        "print(f\"3. Variáveis definidas: {X.shape[1]} features para prever a variável alvo 'blueWins'.\\n\")\n",
        "\n",
        "# 4. Padronização dos Dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "print(\"4. Features padronizadas usando StandardScaler.\")\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 2 ---\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 3: Análise Exploratória de Dados (EDA)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 3: Análise Exploratória de Dados ---\")\n",
        "\n",
        "# Análise de Correlação\n",
        "correlation_matrix = df.corr()\n",
        "blue_wins_correlation = correlation_matrix['blueWins'].sort_values(ascending=False)\n",
        "\n",
        "print(\"1. Correlação das variáveis com a vitória do time azul ('blueWins'):\")\n",
        "print(blue_wins_correlation.head(10)) # Mostra as 10 mais positivas\n",
        "\n",
        "# Remover a própria variável 'blueWins' da lista (correlação 1.0)\n",
        "corr_to_plot = blue_wins_correlation.drop('blueWins')\n",
        "\n",
        "# Pegar as 7 mais positivas e as 7 mais negativas\n",
        "top_positive = corr_to_plot.head(7)\n",
        "top_negative = corr_to_plot.tail(7)\n",
        "top_correlations = pd.concat([top_positive, top_negative])\n",
        "\n",
        "# Plotar o gráfico de barras\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.barplot(\n",
        "    x=top_correlations.values,\n",
        "    y=top_correlations.index,\n",
        "    palette='coolwarm'\n",
        ")\n",
        "plt.title('Top Variáveis Correlacionadas com a Vitória (blueWins)', fontsize=16, pad=20)\n",
        "plt.xlabel('Coeficiente de Correlação Pearson')\n",
        "plt.ylabel('Variável')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n2. Gráfico de correlação (Top Positivas e Negativas) gerado.\")\n",
        "print(\"\\nInsights: 'blueGoldDiff' e 'blueExperienceDiff' têm a correlação mais forte com a vitória.\")\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 3 ---\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 4: Seleção de Modelos e Algoritmos\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 4: Seleção de Modelos e Algoritmos ---\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Divisão dos dados em Treinamento e Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"1. Dados divididos em conjuntos de treino e teste (80/20).\\n\")\n",
        "\n",
        "# 2. Escolha de Algoritmos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "models = {\n",
        "    \"Regressão Logística\": LogisticRegression(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "print(\"2. Modelos selecionados: Regressão Logística, Random Forest e Gradient Boosting.\")\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 4 ---\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 5: Treinamento e Avaliação do Modelo\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 5: Treinamento e Avaliação do Modelo ---\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Treinamento e avaliação iterativa\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Treinando e Avaliando: {name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Armazenar métricas\n",
        "    results[name] = {\n",
        "        \"Acurácia\": accuracy_score(y_test, y_pred),\n",
        "        \"Precisão\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba)\n",
        "    }\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Comparação dos Modelos\n",
        "print(\"\\n--- Comparação Final do Desempenho dos Modelos ---\")\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df.sort_values(by=\"Acurácia\", ascending=False))\n",
        "\n",
        "print(\"\\n--- FIM DA ETAPA 5 ---\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ETAPA 6 e 7: Ajuste Final e Interpretação dos Resultados\n",
        "# ==============================================================================\n",
        "print(\"\\n--- INICIANDO ETAPA 6 e 7: Ajuste Final e Interpretação ---\")\n",
        "\n",
        "# Seleciona o melhor modelo treinado (Random Forest)\n",
        "best_model = models[\"Random Forest\"]\n",
        "\n",
        "# Interpretação dos Resultados - Importância das Features\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': best_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n1. Importância das Features (de acordo com o Random Forest):\")\n",
        "print(feature_importances.head(10)) # Mostrando as 10 mais importantes\n",
        "\n",
        "# --- GRÁFICO 2  ---\n",
        "# Gráfico de barras horizontais\n",
        "\n",
        "top_10_features = feature_importances.head(10)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    x='importance',\n",
        "    y='feature',\n",
        "    data=top_10_features,\n",
        "    palette='mako'\n",
        ")\n",
        "plt.title('As 10 Variáveis Mais Importantes para o Modelo (Random Forest)', fontsize=16, pad=20)\n",
        "plt.xlabel('Nível de Importância')\n",
        "plt.ylabel('Variável')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n2. Gráfico com as 10 features mais importantes gerado.\")\n",
        "\n",
        "print(\"\\n--- Relatório Final e Recomendações ---\")\n",
        "print(\"\"\"\n",
        "Análise e Resultados do Projeto:\n",
        "\n",
        "Esta é a conclusão mais importante para o Tech Lead da Riot Games, vinda da \"Etapa 6 e 7\".\n",
        "\n",
        " O modelo de Random Forest nos diz que as variáveis mais importantes para\n",
        "prever a vitória são, de longe, blueGoldDiff (diferença de ouro) e blueExperienceDiff\n",
        "(diferença de experiência).\n",
        "\n",
        " Redundância Confirmatória: Note que redGoldDiff e redExperienceDiff também estão no topo.\n",
        "Elas são apenas o \"espelho\" das variáveis do time azul (blueGoldDiff é o oposto exato de\n",
        "redGoldDiff). O fato de ambas aparecerem no topo apenas reforça que a diferença de recursos\n",
        "entre os times é o fator mais crítico.\n",
        "\n",
        " O \"Farm\" é Decisivo: As 10 variáveis mais importantes estão todas relacionadas a Ouro (Gold)\n",
        " e Experiência (Experience). Isso significa que, nos primeiros 10 minutos, a vantagem econômica\n",
        " (obtida por \"farmar\" minions e conseguir abates) é um indicador de vitória muito mais forte\n",
        " do que outros objetivos (como o primeiro dragão ou arauto, que não aparecem nesse top 10).\n",
        "\n",
        " Resumo da Conclusão Final (Para o Stakeholder):\n",
        "\"Conseguimos criar um modelo que prevê corretamente o vencedor de 7 em cada 10 partidas usando\n",
        "apenas os dados dos primeiros 10 minutos. A análise confirma que a vantagem econômica é o fator\n",
        "decisivo no início do jogo; a equipe que estabelece uma liderança em ouro e experiência tem\n",
        "uma probabilidade de vitória drasticamente maior.\"\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n--- PROJETO CONCLUÍDO ---\")"
      ]
    }
  ]
}